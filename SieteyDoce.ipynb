{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0864c591",
   "metadata": {},
   "source": [
    "7. Comparar la performance de las 4 variantes de QDA implementadas hasta ahora (no Cholesky) ¿Qué se observa? A modo de opinión ¿Se condice con lo esperado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d5370",
   "metadata": {},
   "source": [
    "### 4 Variantes de QDA comparadas \n",
    "\n",
    "- **`QDA`**: versión base; calcula e inserta los términos de cada clase con bucles más explícitos.\n",
    "- **`TensorizedQDA`**: reduce bucles y vectoriza sobre las observaciones.\n",
    "- **`FasterQDA`**: incrementa la vectorización y el uso de arrays intermedios.\n",
    "- **`EfficientQDA`**: la más vectorizada; concentra el cálculo en pocas operaciones grandes.\n",
    "\n",
    "### ¿Qué cambia entre variantes?\n",
    "\n",
    "Todas implementan la misma regla de decisión QDA; lo que varía es **cómo** se computan, por clase \\(k\\), los términos: $(x-\\mu_k)^{\\top}\\,\\Sigma_k^{-1}\\,(x-\\mu_k)$ y $\\log |(\\Sigma_k)|$\n",
    "\n",
    "haciendo mas precálculo por clase (por ejemplo $\\Sigma_k^{-1}$ y $(\\log|(\\Sigma_k)|)$ y más vectorizaci+on para evitar bucles innecesarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c58a49",
   "metadata": {},
   "source": [
    "### Qué se observó\n",
    "\n",
    "- **Exactitud**: prácticamente igual en las cuatro (si aparece alguna diferencia, es de redondeo numérico).\n",
    "- **Tiempo de cómputo (de más lenta a más rápida):**  \n",
    "  `QDA` < `TensorizedQDA` < `FasterQDA` < `EfficientQDA`\n",
    "  \n",
    " A medida que se precomputan términos por clase y se reemplazan bucles por operaciones vectorizadas disminuye el trabajo repetido y mejora el tiempo.\n",
    "- **Memoria**: las variantes más vectorizadas (en especial `EfficientQDA`) pueden usar más RAM por los intermedios; `TensorizedQDA`/`FasterQDA` suelen ofrecer un buen balance tiempo/RAM en tamaños medianos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e4b14",
   "metadata": {},
   "source": [
    "### Se condice con lo esperado?\n",
    "Sí. En QDA el costo típico es:\n",
    "\n",
    " **Entrenamiento:** $O(K\\,p^3)$ (una inversión/factorización por clase).\n",
    " \n",
    " **Predicción:** $O(n\\,K\\,p^2)$. Precomputar lo que no depende de $x$ y \n",
    " \n",
    "Precomputar lo que **no depende de \\(x\\)** y **vectorizar** (primero en \\(n\\), y cuando es posible también en \\(K\\)) debería acelerar, y eso es lo que se observó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9d95a9",
   "metadata": {},
   "source": [
    "12. Implementar el modelo TensorizedChol paralelizando sobre clases/observaciones según corresponda. Se recomienda heredarlo de alguna de las implementaciones de QDA_Chol, aunque la elección de cuál de ellas queda a cargo del alumno según lo observado en los benchmarks de puntos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import cholesky, solve_triangular\n",
    "\n",
    "class TensorizedChol(QDA_Chol3):\n",
    "    \"\"\"\n",
    "    QDA con Cholesky y vectorización (full-batch).\n",
    "    - Procesa clases × muestras en una sola pasada.\n",
    "    - Usa solve_triangular para L^{-1}.\n",
    "    \"\"\"\n",
    "    def __init__(self, reg=1e-6, priors=None):\n",
    "        super().__init__()\n",
    "        self.reg = float(reg)\n",
    "        self.user_priors = None if priors is None else np.asarray(priors, float)\n",
    "\n",
    "    def _fit_params(self, X, y):\n",
    "        y = np.asarray(y).ravel()\n",
    "        X = np.asarray(X)\n",
    "        p, n = X.shape\n",
    "\n",
    "        # clases y priors\n",
    "        self.classes_ = np.unique(y)\n",
    "        K = self.classes_.size\n",
    "        idx = {c:i for i,c in enumerate(self.classes_)}\n",
    "        if getattr(self, \"log_a_priori\", None) is None:\n",
    "            if self.user_priors is not None:\n",
    "                pri = self.user_priors / self.user_priors.sum()\n",
    "            else:\n",
    "                counts = np.bincount([idx[c] for c in y], minlength=K).astype(float)\n",
    "                pri = counts / counts.sum()\n",
    "            self.log_a_priori = np.log(np.clip(pri, 1e-300, None))\n",
    "\n",
    "        # medias por clase -> (K,p,1)\n",
    "        means = [X[:, y==c].mean(axis=1, keepdims=True) for c in self.classes_]\n",
    "        self.tensor_means = np.stack(means, axis=0)\n",
    "\n",
    "        # Σ_j, Cholesky y L_j^{-1}; log|Σ_j^{-1}| = -2 * sum(log diag(L_j))\n",
    "        I = np.eye(p)\n",
    "        l_invs, logdet_inv = [], []\n",
    "        for c in self.classes_:\n",
    "            Xc = X[:, y==c]\n",
    "            cov_j = np.cov(Xc, bias=True) + self.reg * I   # bias=True para alinear con el TP\n",
    "            L_j  = cholesky(cov_j, lower=True, check_finite=False)\n",
    "            L_inv_j = solve_triangular(L_j, I, lower=True, check_finite=False)\n",
    "            l_invs.append(L_inv_j)\n",
    "            logdet_inv.append(-2.0 * np.log(np.diag(L_j)).sum())\n",
    "        self.tensor_L_inv = np.stack(l_invs, axis=0)\n",
    "        self.logdet_inv   = np.asarray(logdet_inv)\n",
    "\n",
    "    def _scores_block(self, Xb):\n",
    "        # y = L^{-1}(x - μ) ; quad = ||y||^2\n",
    "        unbiased = Xb[None,:,:] - self.tensor_means      # (K,p,nb)\n",
    "        Y = self.tensor_L_inv @ unbiased                 # (K,p,nb)\n",
    "        quad = np.sum(Y*Y, axis=1)                       # (K,nb)\n",
    "        return self.log_a_priori[:,None] + 0.5*self.logdet_inv[:,None] - 0.5*quad\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X = np.asarray(X)                   # full-batch siempre\n",
    "        return self._scores_block(X)        # (K,n)\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = self.decision_function(X)\n",
    "        return self.classes_[np.argmax(scores, axis=0)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CEIA_II",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
